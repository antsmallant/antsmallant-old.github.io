---
layout: post
title: "游戏服务器设计与实现一：百万级同时在线的全区全服游戏"
date: 2024-05-01
last_modified_at: 2024-05-01
categories: [游戏开发]
tags: [gameserver]
---

* 目录  
{:toc}
<br/>

我应该有资格写这篇文章，因为我亲手设计过可以支撑百万级同时在线的全区全服类型的游戏服务器。    

这个游戏是我公司研发的休闲类型游戏，由 penguin 厂独代，研发的时候，经历了 p 厂好几轮的 TDR (Technical Design Review) 。虽然实际上线后 pcu 只有 30 万，但这是游戏运营层面的问题。从服务器运行状况来看，完全是可以稳稳支撑百万以上的。       

弄过这种级别的架构之后，再看原神这种大 dau 的开放世界游戏，或者鸣潮这种号称有 3100 万预约的，都不觉得有啥难的。反而开放世界的游戏偏单机向，服务器负载很小。而像王者荣耀这种 pcu 接近千万级的 moba 也不难，只是个 “开房间类型” 的游戏而已，里面的难点只有网络同步这一块。    

其实大型互联网应用规模是远超游戏的，但游戏有其特殊性，大部分的游戏，至少有部分服务器节点是要做成有状态的，否则没法实现低延迟的高交互。     

下面开始讲具体的工程实践经验。   

本文会假设游戏服务器部署在公有云上，因为目前公有云有足够多便利的设施，大大降低服务器运维的难度，对于服务器开发人员也很友好，可以很容易的把服务器接入 prometheus 这类监控工具，把 log 接入 log 服务。除此外，像阿某云的云数据库，还提供 “数据库洞察” 这种神器，一下子就看得出哪些 sql 查询耗时多，哪些没走索引，对于诊断数据库问题太友好了。  

再比如，公有云提供的 LB（load balance）组件太好用了，比运维自己去搭一堆 lvs 稳定得多，关键是它的池子够大，扛得起你游戏潮汐式的流量变化。LB 除了有外网版本，也有内网版本，用起来很爽。  


---

# 1. 全区全服

此处提到的全区全服，是指所有玩家在一个大通服里一起游戏，就像王者荣耀那样，但战斗的时候并不是所有人在同一个大世界，而是开房间式的，凑够 n 个人就开始一盘游戏（相当于 n 个人在同一个房间内游戏）。   

目前世面上几乎所有的全区全服类型的游戏都可以归类为开房间类型的，区别只是房间人数的多少而已。举几个例子：开放世界的，pve 的时候可以理解为单人房间，pvp 的时候是多人房间；棋牌类型的，n个人一桌，这一桌可以定义为一个房间；moba 类型的，像王者，也是几个人一个房间。    

btw，棋牌类型的，早期的架构都是房间+桌子，整个游戏分 n 个房间，一个房间分 n 个桌子，一个桌子坐 n 个人，但其实放到现在，完全没必要这样设计的，就统一抽象成房间就行了，更容易做负载均衡。  

---

# 2. 架构设计

## 2.1 总体架构
一切的难点都在于量级上，当 pcu 到达百万级的时候，负载均衡成为最关键的问题，整个架构都要设计成可以横向扩容的，在各个层面都要做好负载均衡。   

先画一个典型的架构。   

<br/>
<div align="center">
<img src="https://antsmallant-blog-1251470010.cos.ap-guangzhou.myqcloud.com/media/blog/gamesvr-big-region-architecture.drawio.png"/>
</div>
<center>图1：服务器总体架构</center>
<br/>

---

## 2.2 架构组成

图片已经很明显了。

**网络负载层**  

包含了 nginx 集群，lvs 集群。  

nginx 集群其实就是一个 7 层（http）负载均衡，如果用公有云的话，腾某云就用 CLB，阿某云用 SLB，腾某云号称支持亿级连接，千万级并发，

lvs 集群就是一个 4 层（tcp）负载均衡，自建的话，7 层可以用 dns + nginx 集群，4 层可用 dns + lvs 集群。如果

<br/>

**游戏服务器层**

plazasvr 集群提供一个用户接入点，用户通过 sdksvr 登录成功拿到 token 后，就连接到此接入游戏，除了战斗之外的逻辑，都由 plazasvr 支持。   

battlesvr 集群提供玩家战斗，每个 battlesvr 都支持同时运行 n 个独立的 battle。  

matchsvr 集群提供战斗匹配功能。  

sdksvr 集群提供登录、注册、充值、充值回调、版本更新等功能。  

managesvr 提供后台功能，本质上就是一个 webserver，提供后台管理和数据查看的功能，后台管理主要就包括活动管理、玩家封号、版本更新、玩家数据修改等等，数据查看主要就是看一些数据统计，留存之类的。 

除了以上之外，可能还需要：  

1、根据特定玩法增加一些功能服务器，但在设计的时候，要慎重，不要盲目增加，很多时候，以数据库为中心去设计就 ok 了，很多功能其实可以做到 plazasvr 上，不需要额外的功能服务器，比如好友、公会这些社交功能，以数据库为中心，plazasvr 增加相应的处理模块就行了，plazasvr 之间互相通讯就实现交互了。      

2、数据统计，一般就用大数据那一套，比如 spark，但其实现在不需要自己开发了，直接用 “数数” 之类的第三方，比自己开发更划算。  

<br/>

**数据库层**  






### 2.2.1 lvs 集群

旧式的架构里，会自己做所谓的 gateserver，而多个 gateserver 通过 dns 轮循做负载均衡。这种方式是低效的，且负载不够均衡，出故障调节比较慢。   

更好的做法是直接用 lvs 集群做 tcp 层的负载均衡，用户连接通过 lvs 分散负载到后面的 plazasvr。plazasvr 本身也做容量限制，避免偶尔出现的 lvs 负载不均，前端发现连接被 plazasvr 拒绝，简单的按策略重试一下就 ok 了。   

lvs 负载均衡有好几种策略，

## plazasvr

**负载均衡**

要做到这一层的负载均衡，就要防止用户重复登录，这个可以使用 redis 来实现。  

**用户连接**

plazasvr 主要作为接入点，不执行战斗逻辑，所以对于延迟的要求不高，可以直接使用 tcp。 

---

## battlesvr

**负载均衡**   

天然就支持负载均衡，它的单位粒度足够小，每局 battle 是相互独立的，所以任一局 battle 在任一个 battlesvr 运行都 ok 的。   

**用户连接**   

对于延迟敏感型的游戏，应该直接让用户连接到 battlesvr 上，为了充分的降低延迟，应该使用 udp 连接，找一个靠谱的 rudp 实现即可，比如 kcp，可以做到 “以10%-20%带宽浪费的代价换取了比 TCP快30%-40%的传输速度” [1]。  

对于延迟不敏感的，可以通过 plazasvr 中转战斗消息到 battlesvr，大部分泛休闲类的：如棋牌、卡牌等都可以这样。  

---

## matchsvr

职责上它就是通用的匹配服务器，匹配本身并不是一个负载很重的任务，对于延迟的要求并不高，所以在高负载的时候，服务器内部甚至可以通过把请求排队起来处理，来削峰。  

不过此处考虑到

**负载均衡**

---

## db

---

## 2.3 负载均衡

**lvs**

支撑 4 层（tcp）跟 7 层（http）的负载均衡，

---

## 2.4 容灾

---

## 内存数据库

为了避免宕机带来的影响，服务器要尽可能把状态写到数据库中，一个折衷就是写入内存数据库里，比如 redis。  



---

## matchsvr 的负载均衡

matchsvr 是匹配服务器，开房间类型的游戏，它的最基本流程就是把匹配到一起的 n 个玩家放到某个 battlesvr 上，让它们连上去战斗。  

---

# 3. 服务器自我保护

## 限制单服人数上限

直接用线上机型配置跑一个压力测试，得出一个 80% 资源占用下的在线人数。  

## 自动重连

服务器虽然运行在内网，但内网之间的连接也可能偶尔出现中断的，服务器一定要能自动重连。  

另外，服务器与数据库的连接，也可能偶尔出现中断的，服务器不单要能正常的重连 db，还要做数据写入的失败重试，比如有时候需要在线对数据库做扩容处理，往往会造成1分钟内的读写失败。所以一定要做失败重试，并且设定要重试间隔。   


---

# 4. 压力测试

无论怎么强调都不过分，只有全面的压力测试，才能确保上线稳定，要尽可能模拟足够多的场景，并且在这个阶段，就要把服务器集群接入 prometheus 之类的，看看各方面的指标是否正常，log 也要接入 log 归档服务，自动识别出 log 报错。  

---

# 5. 性能监控

上线前，就要把整个服务器集群都成功的接入 prometheus 之类的 metrics 工具，除了常规的硬件指标：cpu、内存、硬盘、网络，还有业务相关的指标，比如数据相关的收包量、发包量、广播量，各个服的在线人数，战斗中人数，战斗个数，这些都要精确到各个具体的进程上，既要能看大盘，又要能看具体个服。  

做好性能监控，是一个服务端主程的基本修养。它能带来几个基本好处：  

1、发现问题，很多东西是测试不出来的，线上才会出问题，指标可以清楚告诉我们哪里运行不正常了。   

2、扩容参考，运营经常会导量，做活动，作为主程，你就要评估，撑不撑得住，要不要提前扩容。  

3、优化参考，无论做什么优化，都要基于数据。  

---

# 6. log 归档与告警

log 对于排查错误，提早发现错误太重要了。对于线上运营的游戏，我们有几个方面要做好的：  

1、预防问题，要在问题恶化前提前发现，要能在百万同时在线，海量 log 的情况下，发现一行毫不起眼的报错，无论是业务主动输出，还是被捕捉到的 stack 报错之类的。  

2、快速诊断，出现问题，要跟时间赛跑，第一时间通过 log 诊断到病根，然后解决。     

log 也可以拿来统计指标。   

---

# 7. 热更新

无论用什么语言，至少做到配置热更新。用 lua 写逻辑的，至少做到可以热修复 bug。


---

# 8. 玩法实现




---

# 3. 不好的设计

---

## 3.1 数据服务器

经常看到一些文章里面，画的游戏服务器架构图里面会有 dbsvr 这种东西，它的作用大致是作为 gamesvr 和 db 之间的媒介：gamesvr -> dbsvr -> db 。  

其实这是很没必要的做法，dbsvr 的存在只是增加了单点故障的风险，直接 gamesvr -> db 就好了。  

---

## 3.2 用 redis cache 玩家核心数据

todo：展开讲讲 redis 的 aof 以及 bgsave 可以达到的保证。  

这是一个愚蠢的设计（我犯过这个错）。大致做法就是用 redis 完全 cache 玩家数据，读的时候从 redis 先读，读不到就从 mysql 读并写入 redis；写的时候就双写 redis 和 mysql。  

这种做法的初衷就是为了应对读多写少，但副作用太大了，挺容易就造成数据不一致的，特别是涉及玩家财富的东西，不一致是很可怕的。   

我的建议是，redis 不要拿来 cache 玩家数据，玩家数据应该只从一个地方读写，无论你用的是 mongodb, mysql 或其他的。  

问题一：redis 适应做什么呢？

1、全服排行榜，即使规模上千万的排行榜，sortedset 也能胜任，不过要注意的是，对于这种单个大 key 的，在 delete 数据的时候不能一上来就把这个 key delete，当时开发的时候我们做过测试，在 p 厂的 B6 机型上：删除一个member为1400w的zset，需要43秒的时间；删除一个member为4600w的zset，需要129秒的时间。dba 给的建议是循环的删除，我们也是这么做的，没啥问题。  

2、玩家的展示性的数据，比如排行榜上面玩家的一些成就或战力之类的数据，这种数据重要性不高，不一致了问题也不大，反正 db 了存的绝对是对的，redis 的 cache 总可以被更新成正确数据的，前提是我们要对每个 redis key 设置 expire。   

btw，服务器如果是跑在公有云上，都不需要用 redis 了，好多公有云自研的内存数据库都提供兼容 redis 的协议，以及更猛的性能。  

问题二：不使用 redis 作 cache，普通数据库扛得住百万级同时在线吗？   

百万级同时在线，这个变量主要用来衡量写的压力，而每秒登录数主要用来衡量读的压力。因为登录的时候，玩家大部分数据从数据库读出来，登录完后，基本上就剩下写 db 操作了。  

能不能扛得住，就看业务逻辑怎么写，数据库表怎么设计。这是个挺大的话题，需要费比较多口水才能讲得清。  

---

## 3.3 微服务化

这个可能会有争议，但我认为游戏完全没必要微服务化，这只会增加复杂度，增加开发的难度，增加查错的难度。  

能用简单的方式解决问题就用简单的方式，越 stupid 越好。  

对于固执的认为一定要用牛逼的技术解决问题的，要做出牛逼架构的人，我觉得没啥好辩论的，这些人没有 “赢” 的思维，不懂真正的目标是什么，只是在做无效努力。  

---







---

# 参考

[1] skywind3000. kcp.  Available at https://github.com/skywind3000/kcp.   
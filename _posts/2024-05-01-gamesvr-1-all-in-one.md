---
layout: post
title: "游戏服务器工程实践一：百万级同时在线的全区全服游戏"
date: 2024-05-01
last_modified_at: 2024-05-01
categories: [游戏开发]
tags: [gameserver]
---

* 目录  
{:toc}
<br/>

我应该有资格写这篇文章，因为亲手设计过可以支撑百万级同时在线的全区全服类型的游戏服务器架构。  

若干年前我在某公司任职时，参与研发过一款休闲类型的游戏，由 penguin 厂独代。研发的时候，p 厂要求我们的游戏服务器要能支撑百万以上的同时在线，并且也要能够支持在 30 分钟内扩容 100 万在线。  

在经历了 p 厂好几轮的 TDR (Technical Design Review) 后，游戏稳稳上线了。上线后最高同时在线 (pcu) 到达 30 万左右，虽然没有达到 100 万，但从服务器运行状况来看，完全可以稳稳支撑百万以上的。       

做过这种架构之后，再看原神这种大 dau 的开放世界游戏，或者鸣潮这种号称有 3100 万预约的，都不觉得有啥难，反而由于开放世界的游戏偏单机向，服务器负载更小。而像王者荣耀这种 pcu 接近千万级的 moba 也不难，只是个 “开房间类型” 的游戏而已，它的服务器难点主要是在网络同步这一块。       

虽然大型互联网应用的规模是远超游戏的，但游戏也有其特殊性，对于延迟特别敏感，并且往往有一部分服务器节点必须是有状态的，所以游戏服务器架构有自己的难点，不能照搬互联网那一套。     

本文会介绍这类游戏服务器的架构如何搭建，如何实现水平扩容、高可用、容灾的目标。在具体的部署上，也会提供自建和公有云两种方案。    

---

# 1. 全区全服

此处提到的全区全服，是指所有玩家在一个大通服里一起游戏，就像王者荣耀那样，但战斗的时候并不是所有人在同一个大世界，而是开房间式的，凑够 n 个人就开始一盘游戏（相当于 n 个人在同一个房间内游戏）。   

目前世面上几乎所有的全区全服类型的游戏都可以归类为开房间类型的，区别只是房间人数的多少而已。举几个例子：开放世界的，pve 的时候可以理解为单人房间，pvp 的时候是多人房间；棋牌类型的，n个人一桌，这一桌可以定义为一个房间；moba 类型的，像王者，也是几个人一个房间。    

btw，棋牌类型的，早期的架构都是房间+桌子，整个游戏分 n 个房间，一个房间分 n 个桌子，一个桌子坐 n 个人，但其实放到现在，完全没必要这样设计的，就统一抽象成房间就行了，更容易做负载均衡。  

---

# 2. 总体架构

一切的难点都是因为量级太大，当 pcu 到达百万级的时候，水平扩容&负载均衡成为最关键的问题，整个架构的各个组成部分都要设计成可以水平扩容的。除此之外，还要做到高可用、容灾。   

## 2.1 架构图

以下是一个实际可用的服务器架构：      

<br/>
<div align="center">
<img src="https://antsmallant-blog-1251470010.cos.ap-guangzhou.myqcloud.com/media/blog/gamesvr-big-region-architecture.drawio.png"/>
</div>
<center>图1：全区全服游戏服务器总体架构</center>
<br/>

---

## 2.2 工作过程

以 “玩家登录并战斗” 为场景，简单说明一下工作过程:  

<br/>
<div align="center">
<img src="https://antsmallant-blog-1251470010.cos.ap-guangzhou.myqcloud.com/media/blog/gamesvr-big-region-cli-join-battle-seq.png"/>
</div>
<center>图2：玩家登录并战斗流程</center>
<br/>

用文字描述就是：  

1、客户端通过 sdksvr 完成 sdk 登录授权，获得一个 token；  
2、客户端以 token 作为凭证连接上 plazasvr，拉取游戏数据；  
3、客户端发送加入战斗请求到 plazasvr，plazasvr 转发给 matchsvr，matchsvr 完成匹配后，从 battlesvr 集群中选择一台 battlesvr 来承担这局战斗；  
4、客户端连上分配下来的 battlesvr 进行战斗；  

---

# 3. 架构说明

以上架构图里展示的，无论是基础的网络负载层、数据层，或是自己开发的游戏服务层，都设计成可以水平扩容的。  

下面具体讲下架构的各个组成部分：主要作用，如何做到水平扩容、高可用、容灾。   

---

## 3.1 网络负载层

这一层主要是为游戏服务层的 sdksvr 集群、plazasvr 集群提供负载均衡的功能。  

* sdksvr 集群是由一组 web server 构成的集群，它需要 7 层（http）的负载均衡。  

* plazasvr 集群是由一组自己开发的支持 tcp 连接的 server 构成的集群，它需要 4 层（tcp）的负载均衡。  

<br/>

**自建**

nginx 集群使用 dns + nginx 部署，主要是运维的活，采用常规的高可用+容灾方案即可。    

lvs 集群使用 dns + lvs 部署，主要是运维的活，也是采用常规的高可用+容灾方案即可，如果并发连接数特别夸张，需要考虑采用 F5 之类的硬件了。  

<br/>

**公有云**  

用公有云会方便更多，有几个好处：弹性更大，上限更高，扩容简单，更稳定，费用可能更低。   

无论是 4 层还是 7 层，公有云都有对应的产品，一般称为 LB，即 Load Balance。    

比如腾讯云的 CLB，阿里云的 SLB，华为云的 ELB。腾讯云、阿里云我都实际使用过，操作简便，稳定性很高。    

腾讯云在游戏这一块经验比较丰富，前司被 p 厂独代的游戏，用的正是 p 厂自研的 TGW 作为 tcp 负载均衡，表现特别稳定，很丝滑。  

<br/>

---

## 3.2 游戏服务器层

plazasvr，集群部署，支持横向扩展，基本不缓存用户数据，如果宕机，用户重连到别的 plazasvr 即可，基本不丢数据。    

battlesvr，集群部署，支持横向扩展。要分两种情况讨论：1、如果 battle 的状态数据足够小，可以考虑写入 redis 这类内存数据库中，即使宕机，也能恢复 battle；2、但像 moba 类或 fps 类的，基本不可能把场景状态数据写入，一来量大，二来延迟高。结论就是：如果宕机，可能会丢对应 battlesvr 的 n 场战斗数据，但整个集群不受影响。  

matchsvr，主从部署，匹配属于逻辑较复杂，但负载不重的，并且可以把排队数据都写在 redis 这类里面，所以宕机的时候，从进程可以接替主进程，直接从 redis 取数据继续匹配，唯一的影响就是切换过程可能出现十几秒的匹配延迟，但这仍然是可接受的。   

managesvr，集群部署，支持横向扩展，这就是 webserver，无状态，随便宕机，没啥影响。  


### 3.2.1 sdksvr 集群

**作用**   

* 直接面向玩家，玩家请求通过 nginx 集群负载后分发到任一台 sdksvr    
* 为玩家提供登录、注册、充值、版本更新、停服公告等功能    
* 为外部厂商提供充值回调、推广回调等功能   

<br/>

**通讯**   

短连接，http 协议，因为 sdksvr 用 http 服务器实现  

**水平扩容&负载均衡**   

无状态的 web 服务器，天然支持水平扩容，基于前置的 nginx 集群实现负载均衡就行。  

<br/>

**高可用**

无状态的 web 服务器，冗余部署，并配合网络负载层的故障转移，即可实现高可用。   

<br/>

**容灾**

无状态的 web 服务器，宕机也不会丢失数据。  

---

### 3.2.2 plazasvr 集群

**作用**   

* 直接面向玩家，玩家通过 lvs 集群负载后连接到任一台 plazasvr
* 用户通过 sdksvr 登录成功拿到 token 后，由 lvs 负载均衡，接入到其中一台 plazasvr
* 除战斗之外的逻辑，都由 plazasvr 提供
* 玩家可以通过 plazasvr 获得所有的游戏数据，并使用诸如社交、排行之类的功能

<br/>

**通讯**   

* 长连接，tcp 协议，这里并不处理战斗逻辑，对于延迟的要求不高。 

* 使用 protobuf 之类的进行消息序列化，如果用 skynet 框架，则用 sproto 更简便。  

<br/>

**水平扩容**    

用户连接到任一个 plazasvr 都可以，所以可以通过增加 plazasvr 来水平扩容。  

但需要避免同个用户登录到多个 plazasvr，可以通过在 redis 上记录用户的登录服来避免重复登录。  

由于 plazasvr 是直接由网络层的 lvs 负载均衡的，lvs 并不知道 plazasvr 的实际压力，所以它需要自我保护，设定一个合理的人数上限，这个可以通过压测，获得一个 80% 性能消耗的人数阈值。   

plazasvr 内部维护一个在线人数计数，超过阈值就拒绝连接，而客户端在被拒绝后，应该立刻重新请求，让 lvs 重新负载到别的空闲 plazasvr 上。  

<br/>

**负载均衡**

plazasvr 依赖网络负载层的 lvs 集群，实现 4 层（tcp）负载均衡。  

<br/>

**高可用**  

plazasvr 都是独立的，用户连接上任一个 plazasvr 都行，冗余部署，并配合网络负载层的故障转移，即可实现高可用。    

<br/>

**容灾**    

plazasvr 几乎不缓存用户数据，所以可以算是一个无状态服务器，宕机了也不会导致数据丢失。  

---

### 3.2.3 battlesvr 集群

**作用**     

* 直接面向玩家
* 玩家在匹配成功后获得 battlesvr 的连接地址，连接上 battlesvr 进行战斗
* 根据游戏种类，提供 udp 连接或者 tcp 连接
* 提供玩家战斗，每个 battlesvr 都支持同时运行 n 个独立的 battle
* 被 matchsvr 调度使用

<br/>

**通讯**     

* tcp or udp： 

1、对于延迟敏感型的游戏，应该直接让用户连接到 battlesvr 上，为了充分的降低延迟，应该使用 udp 连接，找一个靠谱的 rudp 实现即可，比如 kcp，可以做到 “以10%-20%带宽浪费的代价换取了比 TCP快30%-40%的传输速度” [1]。  

2、对于延迟不敏感的，可以通过 plazasvr 中转战斗消息到 battlesvr，大部分泛休闲类的：如棋牌、卡牌等都可以这样。  

* 使用 protobuf 之类的进行消息序列化，如果用 skynet 框架，则用 sproto 更简便。  

<br/>

**水平扩容**    

每个 battlesvr 都支持运行 n 局 battle，而 battle 之间都是独立的，所以只需要增加 battlesvr，就可以进行水平扩容了。  

<br/>

**负载均衡**   

battlesvr 需要把自己的负载情况写入 etcd 中，matchsvr 订阅此信息，以此为依据进行 battlesvr 的调度。  

<br/>

**高可用**

battlesvr 都是独立的，就像一个个 worker，所以在部署的时候，留有一点冗余，就可以做到高可用了。   

<br/>

**容灾**  

简单说：有状态服务器，宕机会丢战斗数据，基本无法容灾。   

具体要分情况：  

battlesvr 算是这套架构里面唯一的有状态服务器了，而有状态服务器基本上做不到容灾的，一个 battlesvr 宕机，那么在它上面运行着的 battle 也是无法恢复的。  

除非是那种战斗场景状态数量少，延迟不敏感的游戏，比如棋牌、卡牌，这类游戏如果要做到容灾，可以把场景状态实时的写入内存数据库（比如 redis）中，宕机的时候，由备用的 battlesvr 从内存数据库读出场景状态数据来恢复 battle。但其实很少游戏有这么做，基本上挂了就挂了，除非是要用于那种线下的很重要的比赛。  

---

### 3.2.4 matchsvr 集群

**作用**   

* 不直接面向玩家
* 提供战斗匹配功能

匹配服务器，开房间类型的游戏，它的最基本流程就是把匹配到一起的 n 个玩家放到某个 battlesvr 上，让它们连上去战斗。  

职责上它就是通用的匹配服务器，匹配本身并不是一个负载很重的任务，对于延迟的要求并不高，所以在高负载的时候，服务器内部甚至可以通过把请求排队起来处理，来削峰。  


---

### 3.2.5 managesvr

**作用**

* 本质上就是一个 webserver
* 提供后台管理和数据查看的功能
* 后台管理主要就包括活动管理、玩家封号、版本更新、玩家数据修改等等
* 数据查看主要就是看一些数据统计，留存之类的

<br/>

无状态的 http web 服务器，天然支持水平扩容，如果有必要，就在前端加上 nginx 集群即可，但实际上没啥必要，因为 managesvr 的负载一般不会很重的，就是运营内部或者合作发行方使用而已。  

---

### 3.2.6 other server

除了以上之外，可能还需要：  

1、根据特定玩法增加一些功能服务器，但在设计的时候，要慎重，不要盲目增加，很多时候，以数据库为中心去设计就 ok 了，很多功能其实可以做到 plazasvr 上，不需要额外的功能服务器，比如好友、公会这些社交功能，以数据库为中心，plazasvr 增加相应的处理模块就行了，plazasvr 之间互相通讯就实现交互了。      

2、数据统计，一般就用大数据那一套，比如 spark，但其实现在不需要自己开发了，直接用 “数数” 之类的第三方，比自己开发更划算。  

<br/>

---

## 3.3 数据层

这里面包含了 mysql，redis，etcd，数据仓库。  

当说到数据库层面的负载均衡时，我们谈的其实是 sharding 的问题。过去，分库分表总是放在游戏服这一层面，但现在，越来越多的分布式数据库了，它们等于包含了分库分表的能力，业务层需要做的就是指定 sharding key。   

游戏对于数据库的使用是比较简单的，基本上就是当成一个 kv store 而已，所以让数据库帮忙做分库分表是完全没问题的，基本上不会有联表操作，所以读写都很快，几乎相当于水平扩容了的。  

但这里要注意的，仍然写，业务端写数据要有重试机制，不能写失败就放弃了，因为在扩容的时候，往往会断个几十秒的，要有合理的重试机制。  


---

### 3.3.1 mysql

核心 db，用于存储游戏业务数据，是最主要的存储；用其他关系数据库或 nosql 如 mongodb 都 ok；但由于游戏体量大，不可避免要分库分表，要选择能够透明分库分平的数据库，避免把分库分表的逻辑做到游戏服务器，减少复杂度。    

没什么特别情况还是上公有云吧，现在各个公有云都推出了自带 “水平分表” 的云数据库，比如腾讯云的 TDSQL for mysql[3]，

比如 p 厂改了开源的 spider，优化成内部使用的 tspider，这个就支持透明的分库分表，业务层指定 sharding key 就行。  

如果要自建，可以用 ShardingSphere 这款中间件，这篇文章《ShardingSphere 5.x 系列【3】分库分表中间件技术选型》[2]对于各种中间件做了对比，得出的结论就是 ShardingSphere 是最好的选择。   

这个观点我是十分赞同的，特别是在数年前用过某 cat 中间件后，对它大失所望。  

<br/>
<div align="center">
<img src="https://antsmallant-blog-1251470010.cos.ap-guangzhou.myqcloud.com/media/blog/gamesvr-big-region-db-middleware.png"/>
</div>
<center>图2：关于分库分表中间件的选择[2]</center>
<br/>

除了 mysql，还可以考虑 mongodb，游戏数据大部分情况下就是 keyvalue，mongodb 这种文档型 nosql 很适合，另外它本身就支持 shard。像鸣潮用的就是 mongodb，但不清楚具体是用 mongodb 的自动 sharding，还是自己做了分库分表。MongoDB 从 4.2 版本开始支持自定义分片键了，游戏一般不需要范围查询，所以用 uid 作为分片键，且基于 Hash 去做 sharding，可以使用数据分布得很均匀，sharding 效果会很好。    

分库分表有几种方案，根据实现的位置不同，分为：  

1、业务层；  
2、中间件；  
3、数据源；  

中间件跟数据源的业务耦合性都更低，是当下更优的方案，所以下面的方案选择中，都使用中间件或数据源。  

**自建**  

自建的话，可以考虑 

**公有云**

不同的厂商有不同的方案。  

腾讯云的 TDSQL for mysql 集成了水平分表的功能，支持透明的分库分表。  

华为云提供的是一个支持分库分表的数据库中间件，叫 DDM[4]。  

---

### 3.3.2 redis

代表内存数据库，本架构里对内存数据库的读写很重，所以 redis 要选用分布式版本的，或者公有云提供的 redis 兼容的自研内存数据库都 ok 的，关键是性能要能匹配得上业务的需要。  

开源的，以前用过 twemproxy，实际上，现在公有云都有替代产品：集群版，用这个就行了。   

大排行榜的话，还是用单实例 redis 就好，否则数据倾斜会很要命。不过，大排行榜在运营上是不友好的，像王者荣耀也都是分区排行的，这样就不会出现巨型排行榜了。  

---

### 3.3.3 etcd

这个就没有替代了，主要是作为服务器选主，以及服务发现的，按正常的奇数节点部署就 ok，没什么特别的。    

---

### 3.3.4 数据仓库

作用是：存储各种流水日志，产生运营统计报表，比如登录、注册、充值、游戏时长、财富变化、游戏行为等等。数据量会很庞大，存到普通的关系数据库是查不动，也统计不动的。用当下流行的大数据套件实现就行，或者直接接入第三方的比如 “数数” 这样的专门做数据统计的平台。   

---

# 4. 设计细节

## 4.1 服务器自我保护

---

## 4.2 自动重连&失败重试

服务器虽然运行在内网，但内网之间的连接也可能偶尔出现中断的，服务器一定要能自动重连。  

另外，服务器与数据库的连接，也可能偶尔出现中断的，服务器不单要能正常的重连 db，还要做数据写入的失败重试，比如有时候需要在线对数据库做扩容处理，往往会造成1分钟内的读写失败。所以一定要做失败重试，并且要设定合理的重试间隔。   

---

## 4.3 热更新

1、无论用什么语言，至少做到配置热更新。   

2、如果用 lua 写逻辑的，至少做到可以热修复 bug，虽然 lua 有闭包，比较难以更新，但已经有办法的，可以使用 debug 库重新绑定 upvalue 的方式生成新闭包。   

以上目的都是做到更好的运营，减少服务器重启对玩家的影响。  

---

## 4.4 能拉就不要推

客户端与服务端的交互，能拉数据的就不要推，否则以后优化会很麻烦。尽量让客户端发 request 来获取数据，不要让服务端主动 push。这样做的好处是，主动权放到客户端那边，它可以根据不同的运行环境做不同的适配，调整拉取数据的时机，或者有选择性的拉取自己需要的数据，这样更灵活。  

比如同时有 app 端和 h5 端，而 h5 端要轻量化，有些数据是不需要的，那么它可以自己选择拉或不拉一些数据。  

---

## 4.5 docker 化  

对于架构中无状态的部分，完全可以将它 docker 化，这样在扩容，缩容的时候都更敏捷。   

---

## 4.6 版本兼容


---

# 5. 性能与故障排查

## 5.1 压力测试

无论怎么强调都不过分，只有全面的压力测试，才能确保上线稳定，要尽可能模拟足够多的场景，并且在这个阶段，就要把服务器集群接入 prometheus 之类的，看看各方面的指标是否正常，log 也要接入 log 归档服务，自动识别出 log 报错。  

---

## 5.2 监控

上线前，就要把整个服务器集群都成功的接入 prometheus 之类的 metrics 工具，除了常规的硬件指标：cpu、内存、硬盘、网络，还有业务相关的指标，比如数据相关的收包量、发包量、广播量，各个服的在线人数，战斗人数，战斗个数，这些都要精确到各个具体的进程上，既要能看大盘，又要能看具体个服。  

做好性能监控，是一个服务端主程的基本修养。它能带来几个基本好处：  

1、发现问题，很多东西是测试不出来的，线上才会出问题，指标可以清楚告诉我们哪里运行不正常了。   

2、扩容参考，运营经常会导量，做活动，作为主程，你就要评估，撑不撑得住，要不要提前扩容。  

3、优化参考，无论做什么优化，都要基于数据，不要空想，不要纸上谈兵。  

---

## 5.3 log

log 对于排查错误，提早发现错误太重要了。对于线上运营的游戏，有几个方面要做好的：  

1、预防问题，要在问题恶化前提前发现，要能在海量 log 中发现一行毫不起眼的报错，无论是业务主动输出，还是被动输出的 stack 报错。  

2、快速诊断，出现问题，要跟时间赛跑，第一时间通过 log 诊断到病根，以最快的速度解决。     

<br/>

另外，log 也可以拿来统计得到一些指标性的数据，比如像 nginx 的 access log，可以拿来统计接口的调用比例，

---

# 6. 糟糕的设计

下面列举的都是一些（我认为）糟糕的设计。  

---

## 6.1 数据服务器

经常看到一些文章里面，画的游戏服务器架构图里面会有 dbsvr 这种东西，它的作用大致是作为 gamesvr 和 db 之间的媒介：gamesvr -> dbsvr -> db 。  

其实这是很没必要的做法，dbsvr 的存在只是增加了单点故障的风险，直接 gamesvr -> db 就好了。  

---

## 6.2 用 redis cache 玩家核心数据

todo：展开讲讲 redis 的 aof 以及 bgsave 可以达到的保证。  

这是一个愚蠢的设计（我犯过这个错）。大致做法就是用 redis 完全 cache 玩家数据，读的时候从 redis 先读，读不到就从 mysql 读并写入 redis；写的时候就双写 redis 和 mysql。  

这种做法的初衷就是为了应对读多写少，但副作用太大了，挺容易就造成数据不一致的，特别是涉及玩家财富的东西，不一致是很可怕的。   

我的建议是，redis 不要拿来 cache 玩家数据，玩家数据应该只从一个地方读写，无论你用的是 mongodb, mysql 或其他的。  

问题一：redis 适应做什么呢？

1、全服排行榜，即使规模上千万的排行榜，sortedset 也能胜任，不过要注意的是，对于这种单个大 key 的，在 delete 数据的时候不能一上来就把这个 key delete，当时开发的时候我们做过测试，在 p 厂的 B6 机型上：删除一个member为1400w的zset，需要43秒的时间；删除一个member为4600w的zset，需要129秒的时间。dba 给的建议是循环的删除，我们也是这么做的，没啥问题。  

2、玩家的展示性的数据，比如排行榜上面玩家的一些成就或战力之类的数据，这种数据重要性不高，不一致了问题也不大，反正 db 了存的绝对是对的，redis 的 cache 总可以被更新成正确数据的，前提是我们要对每个 redis key 设置 expire。   

btw，服务器如果是跑在公有云上，都不需要用 redis 了，好多公有云自研的内存数据库都提供兼容 redis 的协议，以及更猛的性能。  

问题二：不使用 redis 作 cache，普通数据库扛得住百万级同时在线吗？   

百万级同时在线，这个变量主要用来衡量写的压力，而每秒登录数主要用来衡量读的压力。因为登录的时候，玩家大部分数据从数据库读出来，登录完后，基本上就剩下写 db 操作了。  

能不能扛得住，就看业务逻辑怎么写，数据库表怎么设计。这是个挺大的话题，需要费比较多口水才能讲得清。  

---

## 6.3 微服务化

这个可能会有争议，但我认为游戏完全没必要微服务化，这只会增加复杂度，增加开发的难度，增加查错的难度。  

能用简单的方式解决问题就用简单的方式，越 stupid 越好。  

对于固执的认为一定要用牛逼的技术解决问题的，要做出牛逼架构的人，我觉得没啥好辩论的，这些人没有 “赢” 的思维，不懂真正的目标是什么，只是在做无效努力。  

---

## 7. 架构原则

1、避免单点，在百万级 pcu 下，单点意味着性能瓶颈，也意味着单点故障风险，可能导致整个集群完全停摆。  

2、仔细计算业务请求量，比如计算出每个登录用户平均会有多少次 db 读写，每个在线用户平均每秒会有多少次 db 读写，只有精确掌握这些，才能估算好 db 的容量需求。  


---

# 8. 总结


---

# 9. 参考

[1] skywind3000. kcp.  Available at https://github.com/skywind3000/kcp.   

[2] 云烟成雨TD. ShardingSphere 5.x 系列【3】分库分表中间件技术选型. Available at https://blog.csdn.net/qq_43437874/article/details/135850829, 2024-02-19.    

[3] 腾讯云. TDSQL 水平分表. Available at https://cloud.tencent.com/document/product/557/10521.  

[4] 华为云. 分布式数据库中间件 DDM. Available at https://www.huaweicloud.com/product/ddm.html.  